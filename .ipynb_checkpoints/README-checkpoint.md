# Accenture_Hybrid_Guided_VAE

The [Hybrid Guided VAE](https://arxiv.org/abs/2104.00165) is a method for . [Accenture Labs](https://www.accenture.com/us-en/about/accenture-labs-index) created the Hybrid Guided VAE in collaboration with the [UCI NMI Lab](https://nmi-lab.org/). By open-sourcing the components that we used to enable training SNN models with our method, we hope to encourage adoption to other datasets and problem domains and collaboration for improvements to the methods.

Inclusion and diversity are fundamental to Accenture's culture and core values. As such, we ask that usage of these assets is consistent with [Accenture's commitment to inclusion and diversity](https://www.accenture.com/us-en/about/inclusion-diversity-index) and compliant with Human Rights Laws and Human Rights Principles (as each is defined below).

> "Human Rights Principles" refers to the recognized principles of international human rights as defined in the United Nations Universal Declaration of Human Rights and the United Nations Global Compact.

> “Human Rights Laws” means any applicable laws, regulations, or rules (collectively, “Laws”) that protect human, civil, labor, privacy, political, environmental, security, economic, due process, or similar rights. Where the Human Rights Laws of more than one jurisdiction are applicable or in conflict with respect to the use of these assets, the Human Rights Laws that are most protective of the individuals or groups harmed shall apply.

## Table of Contents

+ [**Process Overview**](#process-overview)
+ [**Getting Data**](#getting-data)
+ [**Training Models**](#training-models)
+ [**Trained models**](#trained-models)
+ [**Training with SLAYER**](#training-with-slayer)
+ [**Licensing**](#licensing)
+ [**How to Contribute**](#how-to-contribute)
+ [**How to Cite**](#how-to-cite)
+ [**Contacts**](#contacts)

## Process Overview


​
To install the required libraries used to help train and run Hybrid Guided VAE models, run the following:
​
```bash
$ pip install -r requirements.txt
```

## Getting Data

**DVSGestures**


**N-MNIST** 

## Training Models


## Trained models


## Licensing
These assets are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0.txt).

## How to Contribute
We welcome community contributions, especially for new models, improvements to the post-processing, and documentation.

If you'd like to create and share new models, models with new datasets, or improvements, you can do so by opening up a pull request.  

## How to Cite

If you use or adopt the models, code, or methods presented here please cite our work as follows:

@misc{stewart2021gesture,
      title={Gesture Similarity Analysis on Event Data Using a Hybrid Guided Variational Auto Encoder}, 
      author={Kenneth Stewart and Andreea Danielescu and Lazar Supic and Timothy Shea and Emre Neftci},
      year={2021},
      eprint={2104.00165},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}


## Contacts

Andreea Danielescu\
​*Future Technologies, Accenture Labs*\
[andreea.danielescu@accenture.com](mailto:@accenture.com?subject=[GitHub])

​Kenneth Stewart\
​*PhD Candidate, University of California, Irvine*\
​[kennetms@uci.edu](mailto:kennetms@uci.edu?subject=[GitHub])